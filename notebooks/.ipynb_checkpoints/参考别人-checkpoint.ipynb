{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import urllib.request\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "GLOVE_EMBEDDING_SIZE = 100\n",
    "HIDDEN_UNITS = 256\n",
    "MAX_INPUT_SEQ_LENGTH = 30\n",
    "MAX_TARGET_SEQ_LENGTH = 30\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "DATA_SET_NAME = 'gunthercox'\n",
    "DATA_DIR_PATH = '../data/gunthercox'\n",
    "WEIGHT_FILE_PATH = f'../models/{DATA_SET_NAME}/word-glove-weights2.hdf5'\n",
    "\n",
    "GLOVE_MODEL = '../glove/glove.6B.100d.txt'\n",
    "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_white_list(_word):\n",
    "    for char in _word:\n",
    "        if char in WHITELIST:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove():\n",
    "    _word2em = {}\n",
    "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
    "    for line in file:\n",
    "        words = line.strip().split(' ')\n",
    "        word = words[0]\n",
    "        embeds = np.array(words[1:], dtype=np.float32)\n",
    "        _word2em[word] = embeds\n",
    "    file.close()\n",
    "    return _word2em\n",
    "\n",
    "word2em = load_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  science.yml\n",
      "processing file:  money.yml\n",
      "processing file:  literature.yml\n",
      "processing file:  sports.yml\n",
      "processing file:  computers.yml\n",
      "processing file:  trivia.yml\n",
      "processing file:  botprofile.yml\n",
      "processing file:  greetings.yml\n",
      "processing file:  conversations.yml\n",
      "processing file:  ai.yml\n",
      "processing file:  emotion.yml\n",
      "processing file:  humor.yml\n",
      "processing file:  psychology.yml\n",
      "processing file:  politics.yml\n",
      "processing file:  gossip.yml\n",
      "processing file:  movies.yml\n",
      "processing file:  history.yml\n",
      "processing file:  food.yml\n"
     ]
    }
   ],
   "source": [
    "target_counter = Counter()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "for file in os.listdir(DATA_DIR_PATH):\n",
    "    filepath = os.path.join(DATA_DIR_PATH, file)\n",
    "    if os.path.isfile(filepath):\n",
    "        print('processing file: ', file)\n",
    "        lines = open(filepath, 'rt', encoding='utf8').read().split('\\n')\n",
    "        prev_words = []\n",
    "        for line in lines:\n",
    "\n",
    "            if line.startswith('- - '):\n",
    "                prev_words = []\n",
    "\n",
    "            if line.startswith('- - ') or line.startswith('  - '):\n",
    "                line = line.replace('- - ', '')\n",
    "                line = line.replace('  - ', '')\n",
    "                next_words = [w.lower() for w in nltk.word_tokenize(line)]\n",
    "                next_words = [w for w in next_words if in_white_list(w)]\n",
    "                if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
    "                    next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
    "\n",
    "                if len(prev_words) > 0:\n",
    "                    input_texts.append(prev_words)\n",
    "\n",
    "                    target_words = next_words[:]\n",
    "                    target_words.insert(0, 'start')\n",
    "                    target_words.append('end')\n",
    "                    for w in target_words:\n",
    "                        target_counter[w] += 1\n",
    "                    target_texts.append(target_words)\n",
    "\n",
    "                prev_words = next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816, 816)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts), len(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'are', 'the', 'laws', 'of', 'thermodynamics'], ['start', 'i', \"'m\", 'not', 'a', 'physicist', ',', 'but', 'i', 'think', 'this', 'has', 'something', 'to', 'do', 'with', 'heat', ',', 'entropy', ',', 'end']]\n",
      "[['what', 'disease', 'does', 'a', 'carcinogen', 'cause'], ['start', 'cancer', '.', 'end']]\n",
      "[['what', 'is', 'a', 'wavelength'], ['start', 'wavelength', 'is', 'the', 'inverse', 'of', 'frequency', '.', 'end']]\n",
      "[['what', 'is', 'thermodynamics'], ['start', 'the', 'branch', 'of', 'physics', 'dealing', 'with', 'the', 'transformation', 'of', 'heat', 'to', 'and', 'from', 'other', 'end']]\n",
      "[['what', 'is', 'chemistry'], ['start', 'the', 'science', 'of', 'mixing', 'chemicals', '.', 'end']]\n",
      "[['what', 'is', 'crystallography'], ['start', 'this', 'is', 'the', 'science', 'dealing', 'with', 'the', 'study', 'of', 'crystals', '.', 'end']]\n",
      "[['what', 'is', 'avogadro', 's', 'number'], ['start', 'it', 'is', 'the', 'number', 'of', 'molecules', 'per', 'mole', '.', 'the', 'numerical', 'value', 'is', 'six', 'point', 'zero', 'end']]\n",
      "[['what', 'is', 'ultrasound'], ['start', 'ultrasonic', 'waves', ',', 'used', 'in', 'medical', 'diagnosis', 'and', 'therapy', ',', 'in', 'surgery', ',', 'etc', '.', 'end']]\n",
      "[['what', 'is', 'bioinformatics'], ['start', 'a', 'fancy', 'name', 'for', 'applied', 'computer', 'science', 'in', 'biology', '.', 'end']]\n",
      "[['what', 'is', 'venus'], ['start', 'in', 'roman', 'mythology', ',', 'the', 'goddess', 'of', 'love', 'and', 'beauty', 'identified', 'with', 'the', 'greek', 'end']]\n",
      "[['what', 'is', 'ichthyology'], ['start', 'we', 'talk', 'about', 'this', 'when', 'we', 'study', 'fishes', '.', 'end']]\n"
     ]
    }
   ],
   "source": [
    "for idx, (input_words, target_words) in enumerate(zip(input_texts, target_texts)):\n",
    "    if idx > 10:\n",
    "        break\n",
    "    print([input_words, target_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word2idx = dict()\n",
    "for idx, word in enumerate(target_counter.most_common(MAX_VOCAB_SIZE)):\n",
    "    target_word2idx[word[0]] = idx + 1\n",
    "\n",
    "if 'unknown' not in target_word2idx:\n",
    "    target_word2idx['unknown'] = 0\n",
    "\n",
    "target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "\n",
    "num_decoder_tokens = len(target_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_decoder_tokens': 1531, 'encoder_max_seq_length': 30, 'decoder_max_seq_length': 32}\n"
     ]
    }
   ],
   "source": [
    "input_texts_word2em = []\n",
    "\n",
    "encoder_max_seq_length = 0\n",
    "decoder_max_seq_length = 0\n",
    "\n",
    "for input_words, target_words in zip(input_texts, target_texts):\n",
    "    encoder_input_wids = []\n",
    "    for w in input_words:\n",
    "        emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
    "        if w in word2em:\n",
    "            emb = word2em[w]\n",
    "        encoder_input_wids.append(emb)\n",
    "\n",
    "    input_texts_word2em.append(encoder_input_wids)\n",
    "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
    "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
    "\n",
    "context = dict()\n",
    "context['num_decoder_tokens'] = num_decoder_tokens\n",
    "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
    "context['decoder_max_seq_length'] = decoder_max_seq_length\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(input_word2em_data, output_text_data):\n",
    "    num_batches = len(input_word2em_data) // BATCH_SIZE\n",
    "    while True:\n",
    "        for batchIdx in range(0, num_batches):\n",
    "            start = batchIdx * BATCH_SIZE\n",
    "            end = (batchIdx + 1) * BATCH_SIZE\n",
    "            encoder_input_data_batch = pad_sequences(input_word2em_data[start:end], encoder_max_seq_length)\n",
    "            decoder_target_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
    "            decoder_input_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE))\n",
    "            for lineIdx, target_words in enumerate(output_text_data[start:end]):\n",
    "                for idx, w in enumerate(target_words):\n",
    "                    w2idx = target_word2idx['unknown']  # default unknown\n",
    "                    if w in target_word2idx:\n",
    "                        w2idx = target_word2idx[w]\n",
    "                    if w in word2em:\n",
    "                        decoder_input_data_batch[lineIdx, idx, :] = word2em[w]\n",
    "                    if idx > 0:\n",
    "                        decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
    "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
    "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
    "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
    "                                                                 initial_state=encoder_states)\n",
    "decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(Xtrain))\n",
    "print(len(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(Xtrain, Ytrain)\n",
    "test_gen = generate_batch(Xtest, Ytest)\n",
    "\n",
    "train_num_batches = len(Xtrain) // BATCH_SIZE\n",
    "test_num_batches = len(Xtest) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 5s 456ms/step - loss: 2.0061 - acc: 0.0347 - val_loss: 1.6087 - val_acc: 0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/topology.py:2379: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm_8/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'encoder_lstm_8/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.7545 - acc: 0.0447 - val_loss: 1.6074 - val_acc: 0.0583\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 1.7202 - acc: 0.0507 - val_loss: 1.6100 - val_acc: 0.0581\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.6922 - acc: 0.0539 - val_loss: 1.6048 - val_acc: 0.0613\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.6643 - acc: 0.0577 - val_loss: 1.5982 - val_acc: 0.0630\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.6352 - acc: 0.0605 - val_loss: 1.5980 - val_acc: 0.0664\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 1.6081 - acc: 0.0626 - val_loss: 1.5942 - val_acc: 0.0684\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 1.5813 - acc: 0.0637 - val_loss: 1.5901 - val_acc: 0.0693\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.5605 - acc: 0.0658 - val_loss: 1.5904 - val_acc: 0.0691\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.5339 - acc: 0.0682 - val_loss: 1.5872 - val_acc: 0.0720\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 1.5119 - acc: 0.0699 - val_loss: 1.5862 - val_acc: 0.0728\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.4878 - acc: 0.0715 - val_loss: 1.5822 - val_acc: 0.0747\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 1.4654 - acc: 0.0749 - val_loss: 1.5822 - val_acc: 0.0732\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.4421 - acc: 0.0767 - val_loss: 1.5860 - val_acc: 0.0745\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.4226 - acc: 0.0785 - val_loss: 1.5806 - val_acc: 0.0771\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.3990 - acc: 0.0809 - val_loss: 1.5799 - val_acc: 0.0791\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.3788 - acc: 0.0820 - val_loss: 1.5774 - val_acc: 0.0776\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 1.3583 - acc: 0.0841 - val_loss: 1.5755 - val_acc: 0.0786\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.3375 - acc: 0.0862 - val_loss: 1.5775 - val_acc: 0.0798\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.3178 - acc: 0.0881 - val_loss: 1.5750 - val_acc: 0.0803\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 1.2990 - acc: 0.0888 - val_loss: 1.5712 - val_acc: 0.0798\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.2761 - acc: 0.0912 - val_loss: 1.5772 - val_acc: 0.0815\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.2607 - acc: 0.0916 - val_loss: 1.5681 - val_acc: 0.0815\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.2374 - acc: 0.0936 - val_loss: 1.5693 - val_acc: 0.0798\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 1.2221 - acc: 0.0940 - val_loss: 1.5713 - val_acc: 0.0830\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 1.1973 - acc: 0.0969 - val_loss: 1.5700 - val_acc: 0.0830\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.1806 - acc: 0.0976 - val_loss: 1.5749 - val_acc: 0.0801\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.1694 - acc: 0.0985 - val_loss: 1.5586 - val_acc: 0.0857\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.1464 - acc: 0.1003 - val_loss: 1.5650 - val_acc: 0.0847\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.1265 - acc: 0.1018 - val_loss: 1.5609 - val_acc: 0.0852\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 1.1096 - acc: 0.1023 - val_loss: 1.5619 - val_acc: 0.0847\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.0908 - acc: 0.1046 - val_loss: 1.5550 - val_acc: 0.0847\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.0732 - acc: 0.1065 - val_loss: 1.5586 - val_acc: 0.0847\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.0569 - acc: 0.1083 - val_loss: 1.5602 - val_acc: 0.0862\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 1.0346 - acc: 0.1100 - val_loss: 1.5581 - val_acc: 0.0859\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.0194 - acc: 0.1117 - val_loss: 1.5580 - val_acc: 0.0857\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 1.0068 - acc: 0.1117 - val_loss: 1.5621 - val_acc: 0.0862\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.9845 - acc: 0.1162 - val_loss: 1.5613 - val_acc: 0.0874\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.9673 - acc: 0.1189 - val_loss: 1.5569 - val_acc: 0.0854\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.9549 - acc: 0.1209 - val_loss: 1.5609 - val_acc: 0.0874\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.9338 - acc: 0.1248 - val_loss: 1.5565 - val_acc: 0.0879\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.9167 - acc: 0.1273 - val_loss: 1.5590 - val_acc: 0.0874\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.9026 - acc: 0.1294 - val_loss: 1.5577 - val_acc: 0.0881\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.8844 - acc: 0.1345 - val_loss: 1.5507 - val_acc: 0.0881\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.8690 - acc: 0.1371 - val_loss: 1.5603 - val_acc: 0.0884\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.8527 - acc: 0.1401 - val_loss: 1.5607 - val_acc: 0.0833\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.8381 - acc: 0.1430 - val_loss: 1.5646 - val_acc: 0.0859\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.8238 - acc: 0.1458 - val_loss: 1.5580 - val_acc: 0.0894\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.8072 - acc: 0.1491 - val_loss: 1.5622 - val_acc: 0.0874\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.7909 - acc: 0.1531 - val_loss: 1.5664 - val_acc: 0.0872\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.7774 - acc: 0.1559 - val_loss: 1.5693 - val_acc: 0.0852\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.7636 - acc: 0.1598 - val_loss: 1.5638 - val_acc: 0.0886\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.7498 - acc: 0.1626 - val_loss: 1.5637 - val_acc: 0.0901\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.7343 - acc: 0.1674 - val_loss: 1.5698 - val_acc: 0.0876\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.7238 - acc: 0.1704 - val_loss: 1.5635 - val_acc: 0.0876\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.7076 - acc: 0.1730 - val_loss: 1.5691 - val_acc: 0.0906\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.6952 - acc: 0.1752 - val_loss: 1.5672 - val_acc: 0.0896\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.6796 - acc: 0.1799 - val_loss: 1.5728 - val_acc: 0.0879\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.6725 - acc: 0.1810 - val_loss: 1.5723 - val_acc: 0.0857\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.6590 - acc: 0.1845 - val_loss: 1.5731 - val_acc: 0.0881\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.6444 - acc: 0.1864 - val_loss: 1.5723 - val_acc: 0.0891\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.6309 - acc: 0.1896 - val_loss: 1.5759 - val_acc: 0.0867\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 116ms/step - loss: 0.6233 - acc: 0.1907 - val_loss: 1.5784 - val_acc: 0.0867\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.6110 - acc: 0.1938 - val_loss: 1.5864 - val_acc: 0.0869\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.6049 - acc: 0.1947 - val_loss: 1.5850 - val_acc: 0.0886\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.5913 - acc: 0.1972 - val_loss: 1.5799 - val_acc: 0.0889\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.5758 - acc: 0.1999 - val_loss: 1.5894 - val_acc: 0.0833\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.5731 - acc: 0.2019 - val_loss: 1.5815 - val_acc: 0.0894\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.5603 - acc: 0.2049 - val_loss: 1.5854 - val_acc: 0.0872\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.5507 - acc: 0.2057 - val_loss: 1.5925 - val_acc: 0.0891\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.5353 - acc: 0.2096 - val_loss: 1.5831 - val_acc: 0.0869\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.5287 - acc: 0.2117 - val_loss: 1.5922 - val_acc: 0.0879\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.5200 - acc: 0.2133 - val_loss: 1.5911 - val_acc: 0.0896\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.5064 - acc: 0.2171 - val_loss: 1.6017 - val_acc: 0.0874\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.5006 - acc: 0.2185 - val_loss: 1.5899 - val_acc: 0.0913\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.4867 - acc: 0.2217 - val_loss: 1.6034 - val_acc: 0.0889\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.4837 - acc: 0.2233 - val_loss: 1.6057 - val_acc: 0.0901\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.4711 - acc: 0.2253 - val_loss: 1.5942 - val_acc: 0.0894\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.4595 - acc: 0.2281 - val_loss: 1.6014 - val_acc: 0.0876\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.4529 - acc: 0.2297 - val_loss: 1.6086 - val_acc: 0.0916\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.4491 - acc: 0.2316 - val_loss: 1.6082 - val_acc: 0.0911\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.4365 - acc: 0.2341 - val_loss: 1.6053 - val_acc: 0.0918\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.4286 - acc: 0.2356 - val_loss: 1.6133 - val_acc: 0.0884\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.4219 - acc: 0.2397 - val_loss: 1.6240 - val_acc: 0.0911\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.4177 - acc: 0.2389 - val_loss: 1.6105 - val_acc: 0.0908\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.4026 - acc: 0.2437 - val_loss: 1.6121 - val_acc: 0.0933\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.3952 - acc: 0.2448 - val_loss: 1.6258 - val_acc: 0.0923\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.3890 - acc: 0.2478 - val_loss: 1.6231 - val_acc: 0.0916\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.3811 - acc: 0.2479 - val_loss: 1.6222 - val_acc: 0.0872\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.3732 - acc: 0.2517 - val_loss: 1.6203 - val_acc: 0.0923\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.3704 - acc: 0.2501 - val_loss: 1.6283 - val_acc: 0.0938\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.3571 - acc: 0.2540 - val_loss: 1.6326 - val_acc: 0.0911\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.3532 - acc: 0.2549 - val_loss: 1.6285 - val_acc: 0.0940\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.3432 - acc: 0.2574 - val_loss: 1.6303 - val_acc: 0.0916\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.3359 - acc: 0.2604 - val_loss: 1.6534 - val_acc: 0.0935\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.3352 - acc: 0.2596 - val_loss: 1.6387 - val_acc: 0.0935\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.3214 - acc: 0.2632 - val_loss: 1.6368 - val_acc: 0.0908\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.3166 - acc: 0.2655 - val_loss: 1.6454 - val_acc: 0.0916\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.3121 - acc: 0.2660 - val_loss: 1.6584 - val_acc: 0.0923\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.3053 - acc: 0.2668 - val_loss: 1.6562 - val_acc: 0.0947\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=WEIGHT_FILE_PATH, save_best_only=True)\n",
    "\n",
    "model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    verbose=1, validation_data=test_gen, validation_steps=test_num_batches, callbacks=[checkpoint])\n",
    "\n",
    "model.save_weights(WEIGHT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GunthercoxWordGloveChatBot(object):\n",
    "    model = None\n",
    "    encoder_model = None\n",
    "    decoder_model = None\n",
    "    target_word2idx = target_word2idx\n",
    "    target_idx2word = target_idx2word\n",
    "    max_decoder_seq_length = None\n",
    "    max_encoder_seq_length = None\n",
    "    num_decoder_tokens = None\n",
    "    word2em = word2em\n",
    "\n",
    "    def __init__(self):\n",
    "        self.max_encoder_seq_length = context['encoder_max_seq_length']\n",
    "        self.max_decoder_seq_length = context['decoder_max_seq_length']\n",
    "        self.num_decoder_tokens = context['num_decoder_tokens']\n",
    "\n",
    "        encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
    "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name=\"encoder_lstm\")\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
    "        encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
    "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        self.model.load_weights(WEIGHT_FILE_PATH)\n",
    "        self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    def reply(self, input_text):\n",
    "        input_seq = []\n",
    "        input_emb = []\n",
    "        for word in nltk.word_tokenize(input_text.lower()):\n",
    "            if not in_white_list(word):\n",
    "                continue\n",
    "            emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
    "            if word in self.word2em:\n",
    "                emb = self.word2em[word]\n",
    "            input_emb.append(emb)\n",
    "        input_seq.append(input_emb)\n",
    "        input_seq = pad_sequences(input_seq, self.max_encoder_seq_length)\n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "        target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
    "        target_seq[0, 0, :] = self.word2em['start']\n",
    "        target_text = ''\n",
    "        target_text_len = 0\n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "            sample_word = self.target_idx2word[sample_token_idx]\n",
    "            target_text_len += 1\n",
    "\n",
    "            if sample_word != 'start' and sample_word != 'end':\n",
    "                target_text += ' ' + sample_word\n",
    "\n",
    "            if sample_word == 'end' or target_text_len >= self.max_decoder_seq_length:\n",
    "                terminated = True\n",
    "\n",
    "            target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
    "            if sample_word in self.word2em:\n",
    "                target_seq[0, 0, :] = self.word2em[sample_word]\n",
    "\n",
    "            states_value = [h, c]\n",
    "        return target_text.strip()\n",
    "\n",
    "    def test_run(self):\n",
    "        print(self.reply('Hello'))\n",
    "        print(self.reply('How are you doing?'))\n",
    "        print(self.reply('Have you heard the news?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "i am interested in a wide variety of topics , and read rather a lot .\n",
      "i am very interested in the war between the states .\n"
     ]
    }
   ],
   "source": [
    "model = GunthercoxWordGloveChatBot()\n",
    "model.test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am a real madrid fan .\n",
      "i am not a battle bot .\n",
      "it is a hypothetical question .\n",
      "the science of mixing chemicals .\n",
      "the science of mixing chemicals .\n",
      "a fancy name by the computer science of the computer .\n",
      "i am not . that is a difference .\n",
      "the science of mixing chemicals .\n",
      "a fancy name by applied computer science in biology .\n",
      "a game played a a round ball .\n"
     ]
    }
   ],
   "source": [
    "for i in input_texts[:10]:\n",
    "    sent = ' '.join(i)\n",
    "    print(model.reply(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the laws of thermodynamics\n",
      "what disease does a carcinogen cause\n",
      "what is a wavelength\n",
      "what is thermodynamics\n",
      "what is chemistry\n",
      "what is crystallography\n",
      "what is avogadro s number\n",
      "what is ultrasound\n",
      "what is bioinformatics\n",
      "what is venus\n"
     ]
    }
   ],
   "source": [
    "for i in input_texts[:10]:\n",
    "    print(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start i 'm not a physicist , but i think this has something to do with heat , entropy , end\n",
      "start cancer . end\n",
      "start wavelength is the inverse of frequency . end\n",
      "start the branch of physics dealing with the transformation of heat to and from other end\n",
      "start the science of mixing chemicals . end\n",
      "start this is the science dealing with the study of crystals . end\n",
      "start it is the number of molecules per mole . the numerical value is six point zero end\n",
      "start ultrasonic waves , used in medical diagnosis and therapy , in surgery , etc . end\n",
      "start a fancy name for applied computer science in biology . end\n",
      "start in roman mythology , the goddess of love and beauty identified with the greek end\n"
     ]
    }
   ],
   "source": [
    "for i in target_texts[:10]:\n",
    "    print(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
